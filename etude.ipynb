{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation et modélisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import des bibliothèques\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import pandas as pd  \n",
    "\n",
    "# Lecture CSV\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Affichage des 3 premières lignes\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les features de chaque individu sont représentées par les huit premiers attributs du dataset et la variable à prédire est 'outcome'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données et de la cible\n",
    "data = df.drop('Outcome', axis=1)\n",
    "target = df['Outcome']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décomposition des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier\n",
    "\n",
    "Le voting Classifier est un méta-classifier qui combine plusieurs modèles, parfois similaires mais souvent conceptuellement différents par vote majoritaire. \n",
    "\n",
    "Pour la suite  nous allons créer trois classifieurs radicalement différents, afin d’essayer d’obtenir le meilleur de chacun.\n",
    "\n",
    "Nous allons créer les trois classifieurs suivants nommés respectivement clf1, clf2 et clf3 :\n",
    "- Un modèle de classe KNeighborsClassifier, avec 3 voisins (n_neighbors=3)\n",
    "- Un modèle RandomForestClassifier, avec le paramètre random_state=123\n",
    "- Un modèle LogisticRegression, avec le paramètre max_iter=1000 pour assurer la convergence du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = RandomForestClassifier(random_state=123)\n",
    "clf3 = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La construction d’un voting classifier se fait à l’aide d’une instance de la classe VotingClassifier qui prend en paramètres :\n",
    "-\tEstimators : une liste contenant pour chaque estimateur un label et le nom de l’estimateur\n",
    "-\tVoting : permet de spécifier la méthode de vote (hard ou soft)\n",
    "\n",
    "\n",
    "Pour rappel : \n",
    "-\tAvec le vote hard : l’étiquette de la classe finale est celle de la classe prédite le plus fréquemment par les modèles de classification. \n",
    "-\tAvec le vote soft : l’étiquette de la classe finale est obtenue en faisant la moyenne des probabilités de classe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vclf = VotingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', clf3)], voting = 'hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tA l’aide de la fonction Kfold, création de cv3 : un cross-validator à 3 parties (folds), avec les paramètres random_state=111 et shuffle = True\n",
    "-\tA l’ide de la fonction cross_validate(), affichage pour chacun des 3 classifieurs individuels ainsi que pour le voting classifier :\n",
    "o\tLa moyenne et l’écart type du score de taux de bonne prédiction(‘accuracy’)\n",
    "o\tLa moyenne et l’écart type du f1-score obtenus par validation croisée avec cv3 sur (X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KNN] \n",
      " Accuracy : 0.71 (+/- 0.02) F1 score : 0.58 (+/- 0.02)\n",
      "[Random Forest] \n",
      " Accuracy : 0.76 (+/- 0.03) F1 score : 0.63 (+/- 0.04)\n",
      "[Logic Regression] \n",
      " Accuracy : 0.76 (+/- 0.02) F1 score : 0.61 (+/- 0.05)\n",
      "[Voting Classifier] \n",
      " Accuracy : 0.77 (+/- 0.00) F1 score : 0.64 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "cv3 = KFold(n_splits=3, random_state=111, shuffle=True)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, vclf], ['KNN', 'Random Forest', 'Logic Regression', 'Voting Classifier']):\n",
    "    scores = cross_validate(clf, X_train, y_train, cv=cv3, scoring=['accuracy', 'f1'])\n",
    "    print(\"[%s] \\n Accuracy : %0.2f (+/- %0.2f)\"% (label, scores['test_accuracy'].mean(), scores['test_accuracy'].std()),\n",
    "          \"F1 score : %0.2f (+/- %0.2f)\"%(scores['test_f1'].mean(), scores['test_f1'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats obtenus montrent que sur nos deux métriques, le Voting Classifier fonctionne sensiblement mieux que le meilleur des modèles individuels.\n",
    "\n",
    "En évaluant individuellement chaque trio de prédictions retournées par les classifieurs, le modèle final parvient à combiner le pouvoir des différents modèles pour produire de meilleurs résultats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Le Stacking est une méthode qui utilise les sorties de différents classifieurs comme entrées d'un nouveau méta-classifieur, défini en amont.\n",
    "Le modèle de Stacking avec scikit-learn est créé à partir de la classe StackingClassifier.\n",
    "Il s'utilise de la même manière que le VotingClassifier, mais un paramètre supplémentaire, final_estimator, permet d'indiquer le modèle à utiliser comme méta-classifieur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StackingClassifier]: \n",
      " Accuracy: 0.76 (+/- 0.02)\n",
      " F1 score: 0.62 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "sclf = StackingClassifier(estimators=[('knn', clf1), ('rf', clf2), ('lr', clf3)], final_estimator=clf3)\n",
    "\n",
    "scores = cross_validate(sclf, X_train, y_train, cv=cv3, scoring=['accuracy', 'f1'])\n",
    "    \n",
    "print(\"[StackingClassifier]: \\n Accuracy: %0.2f (+/- %0.2f)\\n\" % (scores['test_accuracy'].mean(), scores['test_accuracy'].std()),\n",
    "      \"F1 score: %0.2f (+/- %0.2f)\" % (scores['test_f1'].mean(), scores['test_f1'].std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats de validation croisée sont bons et au moins égaux aux performances du meilleur classifieur individuel.\n",
    "\n",
    "Évaluons maintenant nos deux modèles d'Ensemble sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 0.8138528138528138\n",
      "Acc : 0.8008658008658008\n"
     ]
    }
   ],
   "source": [
    "vclf.fit(X_train, y_train)\n",
    "sclf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Acc :\", vclf.score(X_test, y_test))\n",
    "print(\"Acc :\", sclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats obtenus sur l'ensemble de test sont très satisfaisants, pour évaluer l'utilité de nos modèles, comparons-les avec le meilleur classifieur individuel selon les résultats obtenus plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Acc :\", clf2.score(X_test, y_test))\n",
    "## On peut également essayer de remplacer clf2 par clf1 et clf3 pour voir s'ils font mieux.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu des résultats du modèle de RandomForest, nous pouvons conclure que nos modèles d'ensemble permettent de gagner ~0.02 points d'accuracy par rapport à l'utilisation d'un seul modèle.\n",
    "Cet écart n'est pas négligeable, ce qui les rendent très intéressants dans les cas où la performance du modèle est très importante.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projetct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
